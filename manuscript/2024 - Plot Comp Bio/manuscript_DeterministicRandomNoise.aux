\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{eegittins74,eeBasu18}
\citation{Mehlhorn15,SCHULZ20197,WILSON202149}
\citation{eethompson33,eewatkins89,eebridle90}
\citation{eethompson33,eebridle90,eeAgrawal11,eeChapelle11}
\citation{Gershman2018,wilson2014,Findling19}
\citation{wilson2014}
\citation{wilson2014}
\citation{wilson2014}
\citation{wilson2014}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  Schematic of the experiment. (A) Dynamics of an example horizon 6 game. Here the first four trials are forced trials in which participants are instructed which option to play. After the forced trials, participants are free to choose between the two options for the remainder of the game. (B) Example repeated games over the course of the experiment. On average, participants play more than 150 such games, with varying horizon (1 vs 6), uncertainty condition ([1 3] vs [2 2]) and observed rewards. In addition, all games are repeated (as Game 18 and 100 are here) such that participants will be faced with the exact same pattern of forced trials and exact same outcomes from those forced trials twice within each experiment. These repeated games allow us to compute the relative contribution of deterministic and random noise by analyzing the extent to which choices are {\em  consistent} across the repeated games.\relax }}{6}{figure.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:taskfig}{{1}{6}{Schematic of the experiment. (A) Dynamics of an example horizon 6 game. Here the first four trials are forced trials in which participants are instructed which option to play. After the forced trials, participants are free to choose between the two options for the remainder of the game. (B) Example repeated games over the course of the experiment. On average, participants play more than 150 such games, with varying horizon (1 vs 6), uncertainty condition ([1 3] vs [2 2]) and observed rewards. In addition, all games are repeated (as Game 18 and 100 are here) such that participants will be faced with the exact same pattern of forced trials and exact same outcomes from those forced trials twice within each experiment. These repeated games allow us to compute the relative contribution of deterministic and random noise by analyzing the extent to which choices are {\em consistent} across the repeated games.\relax }{figure.caption.4}{}}
\citation{wilson2014}
\newlabel{eq:origmodel}{{1}{8}{Model-based analysis}{equation.0.1}{}}
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(bob): \truncate {\Changestruncatewidth }{Taken together our model-free and model-based analyses agree with previous findings showing increased behavioral variability and increased information seeking in the long horizon condition consistent with humans using random and directed exploration. However, for random exploration, this previous analysis cannot distinguish between deterministic and random sources of noise. For this we analyze the extent to which people's choices are consistent on the repeated games.}}{9}{section*.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \added [id=bob]{ADD C AND D PANELS FOR MODEL-BASED RESULTS HERE} Replication of previous findings. Both $p(\mbox  {low mean})$ (A) and $p(\mbox  {high info})$ (B) increase with horizon suggesting that people use both random and directed exploration in this task. \relax }}{10}{figure.caption.9}\protected@file@percent }
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(bob): \truncate {\Changestruncatewidth }{ADD C AND D PANELS FOR MODEL-BASED RESULTS HERE}}{10}{section*.11}\protected@file@percent }
\newlabel{fig:modelfree}{{2}{10}{\added [id=bob]{ADD C AND D PANELS FOR MODEL-BASED RESULTS HERE} Replication of previous findings. Both $p(\mbox {low mean})$ (A) and $p(\mbox {high info})$ (B) increase with horizon suggesting that people use both random and directed exploration in this task. \relax }{section*.11}{}}
\pgfsyspdfmark {pgfid1}{21066856}{41686219}
\@writefile{loc}{\contentsline {deleted}{Deleted\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{Conversely, if choice is not a deterministic function of the stimulus, participants' choices should be independent, and hence more inconsistent across the repetitions of the game.}}{11}{section*.13}\protected@file@percent }
\pgfsyspdfmark {pgfid4}{38786990}{41595911}
\pgfsyspdfmark {pgfid5}{40212398}{41420799}
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{Conversely, if choice is not entirely driven by a deterministic process and is also driven by random noise, participants' choices should be more inconsistent across the repetitions of the game. Moreover, if decision noise is purely random noise, meaning there is no unobserved deterministic process, we will show that we can actually predict the expected level of choice inconsistencies across repetitions of games by accounting for the known deterministic processes and assuming that the random noise process is independent in repetitions of the game.}}{11}{section*.14}\protected@file@percent }
\pgfsyspdfmark {pgfid6}{23434976}{27432139}
\@writefile{loc}{\contentsline {deleted}{Deleted\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{For [1 3] condition, t(64) = 13.72, p $<$ 0.001 for horizon 1, t(64) = 16.71, p $<$ 0.001 for horizon 6; For [2 2] condition, t(64) = 9.55, p $<$ 0.001 for horizon 1, t(64) = 17.93, p $<$ 0.001 for horizon 6}}{11}{section*.15}\protected@file@percent }
\pgfsyspdfmark {pgfid9}{38786990}{27341831}
\pgfsyspdfmark {pgfid10}{40212398}{27166719}
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{, but rather random noise}}{11}{section*.16}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Model-free analysis suggests that both deterministic and random noise contribute to the choice variability in random exploration. For both the [1 3] (A) and [2 2] (B) condition, people show greater choice inconsistency in horizon 6 than horizon 1. However, the extent to which their choices are inconsistent lies between what is predicted by purely deterministic and random noise, suggesting that both noise sources influence the decision.\relax }}{12}{figure.caption.17}\protected@file@percent }
\newlabel{fig:mf2}{{3}{12}{Model-free analysis suggests that both deterministic and random noise contribute to the choice variability in random exploration. For both the [1 3] (A) and [2 2] (B) condition, people show greater choice inconsistency in horizon 6 than horizon 1. However, the extent to which their choices are inconsistent lies between what is predicted by purely deterministic and random noise, suggesting that both noise sources influence the decision.\relax }{figure.caption.17}{}}
\citation{wilson2014}
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{Furthermore, to account for the fact that $p(\mbox  {low mean})$ is a function of reward difference $\Delta R$ between the two bandits and the information condition $I$, we estimated the conditional probability: $$p(\mbox  {inconsistent}|\Delta R, I) = 2 p(\mbox  {low mean}|\Delta R, I)(1-p(\mbox  {low mean}|\Delta R, I))$$ Then based on the likelihood that each condition ($\Delta R$ vs $I$) occurs in the task $\rho (\Delta R, I)$, we have $$p(\mbox  {inconsistent}) = \DOTSB \sum@ \slimits@ _{\Delta R, I}\rho (\Delta R, I)p(\mbox  {inconsistent}|\Delta R, I)$$}}{13}{section*.18}\protected@file@percent }
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(bob): \truncate {\Changestruncatewidth }{As a negative control of our method for estimating $p(\mbox  {inconsistent})$ for purely random noise, we simulated choices using a decision model that only includes random noise (Equation \ref {eq:origmodel}), and found that $p(\mbox  {inconsistent})$ in this simulated data is not different from our pure random noise prediction in all horizon and uncertainty conditions (p $>$ 0.05, Supplementary Figure S3).}}{13}{section*.19}\protected@file@percent }
\pgfsyspdfmark {pgfid11}{22188282}{21924958}
\@writefile{loc}{\contentsline {replaced}{Replaced\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{Together, our results suggest that both random noise and deterministic noise contribute to the choice variability in random exploration.}}{13}{section*.20}\protected@file@percent }
\pgfsyspdfmark {pgfid14}{38786990}{21834650}
\pgfsyspdfmark {pgfid15}{40212398}{21659538}
\pgfsyspdfmark {pgfid16}{20373820}{15871320}
\@writefile{loc}{\contentsline {replaced}{Replaced\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{provides a lower-bound estimate of deterministic noise and an upper-bound estimate of random noise}}{13}{section*.22}\protected@file@percent }
\pgfsyspdfmark {pgfid19}{38786990}{12862776}
\pgfsyspdfmark {pgfid20}{40212398}{12687664}
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{and random noise}}{13}{section*.23}\protected@file@percent }
\pgfsyspdfmark {pgfid21}{32124382}{8152570}
\@writefile{loc}{\contentsline {replaced}{Replaced\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{between components of the noise that are deterministically driven by the stimulus (`deterministic noise') and components of the noise that are not deterministically driven by the stimulus (`random noise')}}{13}{section*.24}\protected@file@percent }
\pgfsyspdfmark {pgfid24}{38786990}{4900552}
\pgfsyspdfmark {pgfid25}{40212398}{4725440}
\citation{lee2014}
\citation{jags,matjags}
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(bob): \truncate {\Changestruncatewidth }{To model participants' choices on the first free-choice trial, we use a modified version of Equation \ref {eq:origmodel}. }}{14}{section*.26}\protected@file@percent }
\newlabel{eq:newmodel}{{2}{14}{Overview of model}{equation.0.2}{}}
\pgfsyspdfmark {pgfid26}{9246710}{19793117}
\@writefile{loc}{\contentsline {replaced}{Replaced\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{Model validation}}{14}{section*.28}\protected@file@percent }
\newlabel{ch:appendix:bayesrecovery}{{}{14}{\replaced [id=siyu]{Model validation}{Parameter recovery}}{section*.28}{}}
\pgfsyspdfmark {pgfid29}{38786990}{19696321}
\pgfsyspdfmark {pgfid30}{40212398}{19521209}
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(bob): \truncate {\Changestruncatewidth }{This allowed us to quantify whether deterministic and random noise can be identified under ideal conditions where the behavior is generated by the model with known parameters. Full details of this analysis are presented in the Supplementary Materials. }}{14}{section*.29}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \added [id=bob]{FONT SIZE ON LEGEND IS VERY SMALL!}Deterministic noise can recover known deterministic processes that's intentionally omitted by the model. In the reduced model where the deterministic effect of uncertainty condition is omitted from the model, deterministic noise is higher compared to the full model that accounts for the effect of uncertainty. Random noise remains unchanged between the two models.\relax }}{16}{figure.caption.30}\protected@file@percent }
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(bob): \truncate {\Changestruncatewidth }{FONT SIZE ON LEGEND IS VERY SMALL!}}{16}{section*.32}\protected@file@percent }
\newlabel{fig:reducedmodel}{{4}{16}{\added [id=bob]{FONT SIZE ON LEGEND IS VERY SMALL!}Deterministic noise can recover known deterministic processes that's intentionally omitted by the model. In the reduced model where the deterministic effect of uncertainty condition is omitted from the model, deterministic noise is higher compared to the full model that accounts for the effect of uncertainty. Random noise remains unchanged between the two models.\relax }{section*.32}{}}
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{Secondly, we evaluated our hierarchical Bayesian analysis procedure using the `frequentist coverage analysis'. In the coverage analysis, we simulated choices with the fitted parameters from the Hierarchical Bayesian analysis, and then re-fit the simulated choices to see whether we can recover the parameters (Figure \ref {fig:coverage2}, Supplementary Figure S4). The simulation and re-fitting was repeated for 200 times. Then we counted out of the 200 repetitions how many times the true parameter that we simulate the choices from lies in the fitted 95\% confidence interval. If our model fitting is reliable, then the fitted confidence interval should cover the true parameter for more than 95\% of the simulations (this ratio will be referred to as the coverage rate). For random noise, the coverage rate is 100\% for both horizon 1, horizon 6, and the horizon difference. For deterministic noise, the coverage rate is 66\% for horizon 1 and 69\% for horizon 6. By comparing the posterior distributions of parameters that were used to generate simulations and the posterior distribution of recovered parameters, it is clear that our model systematically underestimates deterministic noise (Figure \ref {fig:coverage2}). Despite the underestimation of deterministic noise in both horizons, we could still reliably detect the horizon changes of deterministic noise (coverage rate is 97\%). This is because the underestimation of deterministic noise is partially canceled out when the difference is taken between horizons. For random noise, our model fitting procedure yields a faithful recovery. However, there is a conceptual limitation. Because random noise is modeled as non-stimulus-driven noise, it can include both true stochastic neural noise and possible deterministic noises which do not depend on the stimuli. Because of this, our random noise estimate provides an upper bound of true `random noise' induced by intrinsic stochastic processes in the brain.}}{17}{section*.33}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Parameter recovery over the posterior distribution of random and deterministic noise standard deviations $\sigma _{det}$ and $\sigma _{ran}$. Solid lines are true posterior used to simulate choices. Lighter color shades represent the re-fitted posterior to the simulated choices. Our model fitting procedure faithfully recovers the non-stimulus-driven random noise (A, B), but systematically underestimates deterministic noise in both horizons (D, E). The horizon differences in random noise is also faithfully recovered (C). The horizon differences in deterministic noise is also underestimated but not significant (F).\relax }}{18}{figure.caption.34}\protected@file@percent }
\newlabel{fig:coverage2}{{5}{18}{Parameter recovery over the posterior distribution of random and deterministic noise standard deviations $\sigma _{det}$ and $\sigma _{ran}$. Solid lines are true posterior used to simulate choices. Lighter color shades represent the re-fitted posterior to the simulated choices. Our model fitting procedure faithfully recovers the non-stimulus-driven random noise (A, B), but systematically underestimates deterministic noise in both horizons (D, E). The horizon differences in random noise is also faithfully recovered (C). The horizon differences in deterministic noise is also underestimated but not significant (F).\relax }{figure.caption.34}{}}
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{Next, we tested the ability of our model fitting procedure to recovery parameters from simulated data at the subject level (Supplementary Figure S5 and S6). The correlations between the true vs fitted parameters are significant across participants for all parameters (p $<$ 0.001). The strength of correlation between simulated and fit values are strong for both deterministic noise (R $>$ 0.8) and random noise (R $>$ 0.9). Despite the strong inter-subject correlations, we again observed a systematic underestimation of $\sigma _{det}$ (Supplementary Figure S5 and S6).}}{18}{section*.35}\protected@file@percent }
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{Lastly, in addition to testing how our model performs in parameter ranges around the actual fitted parameters, we tested the limitations of our models in arbitrary combinations of random vs deterministic noises. All combinations of random and deterministic noises with $0 \le \sigma _{det} \le 10$ and $0 \le \sigma _{ran} \le 10$ were tested. In a special case, we evaluated how our model performs when there is only random noise or only deterministic noise (Figure \ref {fig:puredetran}). In the simulation with fully deterministic noise and 0 random noise, our model successfully recovered both random and deterministic noise (Figure \ref {fig:puredetran} C, D), however in the simulation with fully random noise and 0 deterministic noise, although our model successfully recovered random noise, some small proportion of deterministic noise was falsely detected when they should instead be 0 (Figure \ref {fig:puredetran} A, B). However, this phenomenon only exists when the true deterministic noise is 0, once the true deterministic noise is greater than 1, we don't observe this inflation of deterministic noise anymore (Supplementary Figures S7). Apart from this, our model did a fairly good job in recovering all combinations of random and deterministic noises (Supplementary Figures S7).}}{19}{section*.36}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Parameter recovery over the posterior of random noise standard deviation, $\sigma _{ran}$, and deterministic noise standard deviation, $\sigma _{det}$, for purely random noise (top row) and purely deterministic noise (bottom row) games. \relax }}{20}{figure.caption.37}\protected@file@percent }
\newlabel{fig:puredetran}{{6}{20}{Parameter recovery over the posterior of random noise standard deviation, $\sigma _{ran}$, and deterministic noise standard deviation, $\sigma _{det}$, for purely random noise (top row) and purely deterministic noise (bottom row) games. \relax }{figure.caption.37}{}}
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{Overall, we are able to detect both deterministic and random noises using our model to a satisfactory extent. Our model provides a lower bound for deterministic noise and an upper bound for random noise. In addition, We see better parameter recovery for random noise than deterministic noise. This is likely because we effectively have half as many trials for deterministic noise. In particular, while we generate two samples of random noise for each repeated game pair, we only generate one sample of deterministic noise, which by definition is the same in both of the repeated games. }}{20}{section*.38}\protected@file@percent }
\pgfsyspdfmark {pgfid31}{28053511}{43455691}
\@writefile{loc}{\contentsline {replaced}{Replaced\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{Numerically,}}{21}{section*.40}\protected@file@percent }
\pgfsyspdfmark {pgfid34}{38786990}{43365383}
\pgfsyspdfmark {pgfid35}{40212398}{43190271}
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{By computing the posterior distribution of $\sigma ^2_{det}/(\sigma ^2_{det}+\sigma ^2_{ran})$, our data suggests that 14.25\% of the variability in random exploration is accounted for by deterministic noise ([4.90\%, 28.81\%], 95\% CI).}}{21}{section*.41}\protected@file@percent }
\pgfsyspdfmark {pgfid36}{10078014}{33477835}
\@writefile{loc}{\contentsline {replaced}{Replaced\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{similar}}{21}{section*.42}\protected@file@percent }
\pgfsyspdfmark {pgfid39}{38786990}{33387527}
\pgfsyspdfmark {pgfid40}{40212398}{33212415}
\pgfsyspdfmark {pgfid41}{19535999}{32052427}
\@writefile{loc}{\contentsline {replaced}{Replaced\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{very similar}}{21}{section*.43}\protected@file@percent }
\pgfsyspdfmark {pgfid44}{38786990}{30094743}
\pgfsyspdfmark {pgfid45}{40212398}{29919631}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \added [id=bob]{TITLE ON B AND D SHOULD SAY `CHANGE IN RANDOM NOISE'}Model based analysis showing the posterior distributions over the group-level mean of the standard deviations of random and deterministic noise. Both random (A, B) and deterministic (C,D) noises are nonzero (A, C) and change with horizon (B, D). However, random noise has both a greater magnitude overall (A, C) and a greater change with horizon (B, D) than deterministic noise.\relax }}{22}{figure.caption.44}\protected@file@percent }
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(bob): \truncate {\Changestruncatewidth }{TITLE ON B AND D SHOULD SAY `CHANGE IN RANDOM NOISE'}}{22}{section*.46}\protected@file@percent }
\newlabel{fig:mb1}{{7}{22}{\added [id=bob]{TITLE ON B AND D SHOULD SAY `CHANGE IN RANDOM NOISE'}Model based analysis showing the posterior distributions over the group-level mean of the standard deviations of random and deterministic noise. Both random (A, B) and deterministic (C,D) noises are nonzero (A, C) and change with horizon (B, D). However, random noise has both a greater magnitude overall (A, C) and a greater change with horizon (B, D) than deterministic noise.\relax }{section*.46}{}}
\citation{Wilson2019}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Model based analysis showing the posterior distributions over the ratio of the group-level mean of the standard deviations of random and deterministic noise between horizon 6 and horizon 1 respectivelly. The ratio in the standard deviations of noise between horizon 6 and horizon 1 is similar for random and deterministic noise.\relax }}{23}{figure.caption.47}\protected@file@percent }
\newlabel{fig:ratio}{{8}{23}{Model based analysis showing the posterior distributions over the ratio of the group-level mean of the standard deviations of random and deterministic noise between horizon 6 and horizon 1 respectivelly. The ratio in the standard deviations of noise between horizon 6 and horizon 1 is similar for random and deterministic noise.\relax }{figure.caption.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces  Our model accounts for all qualitative patterns of the data, namely, p(high info) and p(low mean) increase as a function of horizon, p(inconsistent) increases as a function of horizon for both [1 3] and [2 2] conditions and lies between the pure random and pure deterministic noise prediction.\relax }}{24}{figure.caption.49}\protected@file@percent }
\newlabel{fig:mb3}{{9}{24}{Our model accounts for all qualitative patterns of the data, namely, p(high info) and p(low mean) increase as a function of horizon, p(inconsistent) increases as a function of horizon for both [1 3] and [2 2] conditions and lies between the pure random and pure deterministic noise prediction.\relax }{figure.caption.49}{}}
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{in}}{24}{section*.51}\protected@file@percent }
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{Specifically, we tested the following 6 models (Note that the $\sigma ^{ran}_{horizon},\sigma ^{det}_{horizon}$ model is our original full model).}}{24}{section*.52}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Variants of the model.\relax }}{24}{table.caption.53}\protected@file@percent }
\newlabel{tab:models}{{1}{24}{Variants of the model.\relax }{table.caption.53}{}}
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{ The posterior distributions over the group-level means of the deterministic and random noise standard deviation $\sigma _{det}$ and $\sigma _{ran}$ (when they exist) in these model variants are shown in Supplementary Figure S9. We again simulated choices using fitted parameters from these models and repeated the model-free analysis on the simulated data. }}{25}{section*.54}\protected@file@percent }
\pgfsyspdfmark {pgfid46}{9520399}{43986532}
\@writefile{loc}{\contentsline {replaced}{Replaced\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{behavior}}{25}{section*.55}\protected@file@percent }
\pgfsyspdfmark {pgfid49}{38786990}{43896224}
\pgfsyspdfmark {pgfid50}{40212398}{43721112}
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{ Moreover, we examined if our model can indeed qualitatively capture whether deterministic and random noise are present or not and whether either types of noise is dependent on horizon. To test this, we simulated choices from each of the 6 models, and then fit the simulated choices with our original full model. The simulation was repeated 50 times for each model. Indeed, we showed that our model can capture both the existence of random and deterministic noise, and whether each noise changes with horizon condition (Figure \ref {fig:6model}), with only one exception that our model falsely detected a small fraction of deterministic noise when no deterministic noise was present (Figure \ref {fig:6model}, S). This phenomenon was also examined and discussed in the section "Model validation" above. }}{25}{section*.56}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces  Our model qualitatively captures whether deterministic and random noise are present or not and whether either types of noise is dependent on horizon. A-D. both deterministic and random noise are horizon dependent, E-H. only random noise is horizon dependent, I-L. only deterministic noise is horizon dependent, M-P. neither random nor deterministic noise is horizon dependent, Q-T. only deterministic noise is assumed to be present, U-X. only random noise is assumed to be present.\relax }}{26}{figure.caption.57}\protected@file@percent }
\newlabel{fig:6model}{{10}{26}{Our model qualitatively captures whether deterministic and random noise are present or not and whether either types of noise is dependent on horizon. A-D. both deterministic and random noise are horizon dependent, E-H. only random noise is horizon dependent, I-L. only deterministic noise is horizon dependent, M-P. neither random nor deterministic noise is horizon dependent, Q-T. only deterministic noise is assumed to be present, U-X. only random noise is assumed to be present.\relax }{figure.caption.57}{}}
\citation{drugowitsch16}
\citation{Pouget12}
\citation{Musall2019}
\@writefile{loc}{\contentsline {added}{Added\nobreakspace  {}(bob): \truncate {\Changestruncatewidth }{One interpretation for this low level of deterministic noise is that most of the variability in random exploration is truly random. Such a random noise interpretation, would be consistent with recent work showing that variability in perceptual decisions may be driven by imperfections in mental inference \cite  {drugowitsch16}. In this view, apparently random behavior is not due to sensory processing or response selection, but to suboptimal computations in the brain. Although suboptimal inference is different from simply adding random noise to neural circuitry\citep  {Pouget12}, as long as the suboptimality in neural computation is not a deterministic function of the stimuli, it is a form of random noise in our definition. Indeed, a strong interpretation of this hypothesis would suggest that randomness in explore-exploit behavior is due to imperfect inference about the correct course of action. In the context of the Horizon Task, such computational errors would likely be larger in the long horizon condition as the correct course of action in these cases is much harder to compute CITE DEEP EXPLORATION PAPER.}}{27}{section*.59}\protected@file@percent }
\citation{Bair1996}
\newlabel{eq:noise1}{{3}{28}{Discussion}{equation.0.3}{}}
\newlabel{eq:noise2}{{4}{28}{Discussion}{equation.0.4}{}}
\newlabel{eq:noise3}{{5}{28}{Discussion}{equation.0.5}{}}
\citation{wilson2014}
\citation{wilson2014}
\pgfsyspdfmark {pgfid51}{35919790}{18940641}
\@writefile{loc}{\contentsline {deleted}{Deleted\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{driven}}{29}{section*.62}\protected@file@percent }
\pgfsyspdfmark {pgfid54}{38786990}{18850333}
\pgfsyspdfmark {pgfid55}{40212398}{18675221}
\citation{wilson2014}
\citation{psychtoolbox1,psychtoolbox2}
\citation{wilson2014}
\citation{hbm1}
\pgfsyspdfmark {pgfid56}{3552215}{39144331}
\@writefile{loc}{\contentsline {replaced}{Replaced\nobreakspace  {}(siyu): \truncate {\Changestruncatewidth }{deterministic noise from random noise.}}{31}{section*.65}\protected@file@percent }
\pgfsyspdfmark {pgfid59}{38786990}{39054023}
\pgfsyspdfmark {pgfid60}{40212398}{38878911}
\citation{jags}
\citation{lee_wagenmakers_2014}
\citation{lee_wagenmakers_2014}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Model parameters, priors, hyperparameters and hyperpriors. \relax }}{32}{table.caption.67}\protected@file@percent }
\newlabel{tab:pars2}{{2}{32}{Model parameters, priors, hyperparameters and hyperpriors. \relax }{table.caption.67}{}}
\bibstyle{plainnat}
\bibdata{Refs/refs}
\bibcite{eeAgrawal11}{{1}{2011}{{Agrawal and Goyal}}{{}}}
\bibcite{hbm1}{{2}{2005}{{Allenby et~al.}}{{Allenby, Rossi, and McCulloch}}}
\bibcite{Bair1996}{{3}{1996}{{Bair and Koch}}{{}}}
\bibcite{eeBasu18}{{4}{2018}{{Basu et~al.}}{{Basu, Senellart, and Bressan}}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Schematic of the hierarchical Bayesian model using notation of \cite  {lee_wagenmakers_2014}\relax }}{33}{figure.caption.69}\protected@file@percent }
\newlabel{fig:model}{{11}{33}{Schematic of the hierarchical Bayesian model using notation of \cite {lee_wagenmakers_2014}\relax }{figure.caption.69}{}}
\bibcite{Pouget12}{{5}{2012}{{Beck et~al.}}{{Beck, Ma, Pitkow, Latham, and Pouget}}}
\bibcite{psychtoolbox1}{{6}{1997}{{Brainard}}{{}}}
\bibcite{eebridle90}{{7}{1990}{{Bridle}}{{}}}
\bibcite{eeChapelle11}{{8}{2011}{{Chapelle and Li}}{{}}}
\bibcite{jags}{{9}{2016}{{Depaoli et~al.}}{{Depaoli, Clifton, and Cobb}}}
\bibcite{drugowitsch16}{{10}{2016}{{Drugowitsch et~al.}}{{Drugowitsch, Wyart, Devauchelle, and Koechlin}}}
\bibcite{Findling19}{{11}{2019}{{Findling et~al.}}{{Findling, Skvortsova, Dromnelle, Palminteri, and Wyart}}}
\bibcite{Gershman2018}{{12}{2018}{{Gershman}}{{}}}
\bibcite{eegittins74}{{13}{1974}{{Gittins and Jones}}{{}}}
\bibcite{lee2014}{{14}{2014{a}}{{Lee and Wagenmakers}}{{}}}
\bibcite{lee_wagenmakers_2014}{{15}{2014{b}}{{Lee and Wagenmakers}}{{}}}
\bibcite{Mehlhorn15}{{16}{2015}{{Mehlhorn et~al.}}{{Mehlhorn, Newell, Todd, Lee, Morgan, Braithwaite, Hausmann, Fiedler, and Gonzalez}}}
\bibcite{Musall2019}{{17}{2019}{{Musall et~al.}}{{Musall, Kaufman, Juavinett, Gluf, and Churchland}}}
\bibcite{psychtoolbox2}{{18}{1997}{{Pelli}}{{}}}
\bibcite{SCHULZ20197}{{19}{2019}{{Schulz and Gershman}}{{}}}
\bibcite{matjags}{{20}{2011}{{Steyvers}}{{}}}
\bibcite{eethompson33}{{21}{1933}{{Thompson}}{{}}}
\bibcite{eewatkins89}{{22}{1989}{{Watkins}}{{}}}
\bibcite{wilson2014}{{23}{2014}{{Wilson et~al.}}{{Wilson, Geana, White, Ludvig, and Cohen}}}
\bibcite{Wilson2019}{{24}{2019}{{Wilson and Collins}}{{}}}
\bibcite{WILSON202149}{{25}{2021}{{Wilson et~al.}}{{Wilson, Bonawitz, Costa, and Ebitz}}}
\gdef \@abspage@last{36}
