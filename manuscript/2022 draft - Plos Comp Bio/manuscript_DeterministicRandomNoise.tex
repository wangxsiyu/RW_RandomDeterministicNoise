\documentclass[12pt]{article}
\usepackage{hyperref}
\usepackage[authoryear, round,sort,comma,numbers]{natbib}
\usepackage{times}
\usepackage{color}
\usepackage{apalike}
\usepackage{graphicx}
\usepackage{authblk}
\usepackage{amsmath}
\usepackage[font={sf,small}]{caption}
\usepackage{amssymb}
\usepackage{float}

\newcommand{\specialcell}[2][c]{%
	\begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}
\setlength{\textheight}{9.3in}
\setlength{\textwidth}{7in}
\setlength{\footskip}{0.5in}
\setlength{\topmargin}{-0.5in}
\setlength{\headheight}{0.2in}
\setlength{\headsep}{0in}
\setlength{\parindent}{1pc}
\setlength{\oddsidemargin}{-0.25in}
\setlength{\evensidemargin}{-0.25in}
\renewcommand{\baselinestretch}{1.5}
\usepackage{float}

% control the fontsize
\PassOptionsToPackage{textsize=scriptsize}{todonotes}
%\usepackage[final]{changes}
\usepackage{changes}
\definechangesauthor[name={Siyu Wang}, color=red]{siyu}

\usepackage{xpatch}

%\usepackage{unravel}
%\unravelsetup{max-action=1000, max-input=1000, max-output=1000}
\providecommand\unravel[1]{#1}


% auto insert "comment"
\makeatletter
\xpatchcmd\replaced
{\setkeys{Changes@replaced}{#1}}
{\setkeys{Changes@replaced}{comment={(was): \protect\truncateto{10}{#3}}, #1}}
{}{}
\xpatchcmd\deleted
{\setkeys{Changes@deleted}{#1}}
{\setkeys{Changes@deleted}{comment={(deleted): \protect\truncateto{10}{#2}}, #1}}
{}{}

% fix \listofchanges
\xpatchcmd\ChangesListline
{0px}
{0pt}
{}{}


\newcounter{truncate}
\newcounter{truncate@max}

% truncate #2 to leave at most first #1 words
\def\truncateto#1#2{%
	\setcounter{truncate}{0}%
	\setcounter{truncate@max}{#1}%
	\truncate@loop{#2}%
}

\def\truncate@loop#1{%
	\ifnum\c@truncate=\c@truncate@max
	\def\next{[...]}% tail
	\else
	\in@{ }{#1}%
	\ifin@
	\stepcounter{truncate}%
	\truncate@split#1\@nil
	\else
	\def\next{#1}%
	\fi
	\fi
	\next
}

\def\truncate@split#1 #2\@nil{%
	\def\next{#1 \truncate@loop{#2}}%
}
\makeatother

\makeatletter
\setdeletedmarkup{\@gobble{#1}}
\makeatother

\title{\replaced[id=siyu]{Separating random and deterministic sources of computational noises in explore-exploit decisions}{The nature of decision noise in random exploration}}
\author[1,\textcurrency]{Siyu Wang}
\author[1,2,3]{Robert C. Wilson}


\affil[1]{Department of Psychology, University of Arizona, Tucson AZ, USA}
\affil[2]{Neuroscience and Physiological Sciences Graduate Interdisciplinary Program, University of
	Arizona, Tucson AZ, USA}
\affil[3]{Cognitive Science Program, University of Arizona, Tucson AZ, USA}
\affil[ \textcurrency]{Current Address: Laboratory of Neuropsychology, National Institute of Mental Health, National Institutes of Health, Bethesda MD, USA}

\date{\today}

\begin{document}
	\maketitle
	
	\newpage
	\begin{abstract}
		Human decision making is inherently variable. While this variability is often seen as a sign of suboptimality behavior, recent work suggests that variability can actually be adaptive. An example arises when we must choose between exploring unknown options or exploiting options we know well. A little randomness in these `explore-exploit' decisions is remarkably effective as it encourages us to explore options we might otherwise ignore. Recent work suggests that people may actually use such `random exploration' in practice, increasing their behavioral variability when it is more valuable to explore. 
		%Other work, however, suggests that variability in human behavior is not always random, and is instead driven by deterministic factors (such as repeating past actions) 
		A key question is whether the variability in random exploration is actually random. That is, is random exploration driven by stochastic processes in the brain or by some unobserved deterministic process that we have failed to account for when measuring behavioral variability? By designing an explore-exploit task in which, unbeknownst to them, participants are presented with the exact same choice twice, we provide a partial answer to this question. \added[id=siyu]{We built a novel computational model which could detect and separate previously unobserved deterministic processes from random noise, without having to make a priori assumptions about the nature of the deterministic process. } In particular, we find evidence that around 15$\%$ of the variability in random exploration can be accounted for by deterministic processing of the stimulus. This still leaves open the possibility that much of random exploration is truly `random', but narrows the window of opportunity for \added[id=siyu]{true} stochastic processes to explain this behavior. \added[id=siyu]{Moreover, our results suggest that both deterministic noise and random noise change proportionally to each other as the planning horizon changes. This sheds light on a common noise gating mechanism that is at play in random exploration. Our work takes us one step closer to understanding of the nature of decision noise in explore-exploit decisions.}
		
		%suggests that at least some `random' exploration is not random, but leaves open the possibility that the 
		%However, it is unclear whether this variability is truly random
		%From a modeling perspective, behavioral variability is essentially the variance that can not be explained by a model and is modeled as the level of decision noise. However, what we have called "decision noise" in previous researches could actually just be missing deterministic components from the model, it is difficult to tell whether decision noise truly arises from a stochastic process. Here we show that, while both random and deterministic noise drive variability in behavior, the noise driving random exploration is predominantly random. This suggests that random exploration depends on adaptive noise processes in the brain which are subject to cognitive control.
		
	\end{abstract}
	\newpage
	\section*{Introduction}
	
	%BOB SAYS: IN GENERAL, NEED TO GO THROUGH THE PAPER AND MAKE SURE THAT `RANDOM' NOISE IS REPLACES WITH `NOT A DETERMINISTIC FUNCTION OF THE STIMULUS' OR SOMETHING LIKE THAT
	%SIYU Says: We can define "random noise" as "not a deterministic funciton of the stimulus" at the beginning, and use the term "random noise" in the results section. It feels a little lengthy to use "not a deterministic function of the stimulus" in the results section each time. I changed a few of them back to "random noise" in the results section, in places that I think random noise is better. See if you like the changes. 
	
	%(BOB SAYS: TAKE OR LEAVE THIS CHANGE TO DATE, BUT SETTING UP AS A DATE ALLOWS YOU TO TALK ABOUT AVOID YOUR EX LATER ON, WHICH MAY BE A BETTER EXAMPLE OF A DETERMINISTIC PROCESS!).
	% Siyu Say: I kept this.
	
	Imagine trying to decide where to go to dinner on a date, you can go to your favorite restaurant, the one you both really enjoy and always go to, or you can try a new restaurant that you know nothing about. Such decisions, in which we must choose between a well-known `exploit' option and a lesser known `explore' option, are known as explore-exploit decisions.  From a theoretical perspective, making optimal explore-exploit choices, i.e. choices that maximize long-term reward, is computationally intractable in most cases \citep{eegittins74, eeBasu18}. In part because of this difficulty, there is considerable interest in how humans and animals solve the explore-exploit dilemma in practice \added[id=siyu]{\citep{Mehlhorn15, SCHULZ20197,WILSON202149}}.
	%\citep{eeauer02,eegittins79,eekrebs78,eethompson33, eewatkins89, eebridle90,eemeyer95, eebanks97,eefrank09, eesteyvers09, eelee11, eepl12,eezhang13,eedaw06, eepl11, wilson2014}
	
	One particularly effective strategy for solving the explore-exploit dilemma is choice randomization \citep{eethompson33, eewatkins89, eebridle90} \added[id=siyu]{, also known as random exploration}. In this strategy, \deleted[id=siyu]{the decision process between exploration and exploitation is corrupted by `decision noise', meaning that }high value `exploit' options are not always chosen and exploratory choices are sometimes made by chance. \added[id=siyu]{In modeling terms, random exploration works by adding 'decision noise' to the value of the options such that sub-optimal exploratory options can sometimes have a higher total score (i.e., value + noise) than the exploit option and get chosen.} \replaced[id=siyu]{Such}{In theory, such} random exploration, is surprisingly effective and, if implemented correctly, can come close to optimal performance \added[id=siyu]{in theory}\citep{eethompson33, eebridle90, eeAgrawal11, eeChapelle11}.
	
	It has recently been shown that humans appear to use random exploration and can increase such decision noise when it is more beneficial to explore \citep{Gershman2018, wilson2014}. In one of these tasks, known as the Horizon Task, the key manipulation is the horizon condition, i.e. the number of decisions remaining for the participant to make. Increasing the horizon makes exploration more valuable as there is more time to use the information gained by exploration to maximize future rewards. For example, if you are leaving town tomorrow (short horizon), you will probably exploit the restaurant you know and love, but if you are in town for a while (long horizon), you would be more likely to explore the new restaurant. Using such a horizon manipulation it has been shown that people's behavior is more variable in long horizons than short horizons, suggesting that they use adaptive decision noise to solve the explore-exploit dilemma \citep{wilson2014}. 
	
	\replaced[id=siyu]{One limitation, however, is that it is difficult to tell whether what we have called 'decision noise' in previous research is truly a random noise.}{One limitation of this previous work, is that it is difficult to tell whether what is measured as decision noise is truly random.} That is, whether behavioral variability is due to intrinsic stochastic processes in the brain or whether it is due to deterministic processes that we \replaced[id=siyu]{failed to observe}{simply have not observed}. \added[id=siyu]{Decision noise as defined in previous researches are more or less a quantification of what's not predictable by the model. A missing deterministic component from the model could give rise to variability in behavior that might appear to be a random noise.} For example, in the restaurant example, my usual preference for one restaurant or another may be overruled if I see an ex romantic partner going into one of them. Avoiding an ex is a deterministic process, but if we fail to take ex's presence into account as scientists modeling the decision, then over a series of such decisions where the ex is present or not, we would mistakenly attribute the ensuing `variability' in choice to randomness.
	
	
	
	%because noise in previous work is defined as the component of the decision process that cannot be accounted for by a model. 
	%, 
	%For example, in the restaurant case above, if you happen to spot an old friend walking in to one of the restaurants, you may be more likely to follow them in. Such a process would be deterministic, in that it is driven by an observable stimulus, but unless a model of your behavior incorporated the presence of your friend, 
	
	%. If the model did not consider that the agent is favoring the behavior of following a friend in a deterministic way, the behavior of going to a less favorable restaurant because of a friend will appear to be `random' when it is really a deterministic effect. Hence this deterministic factor will be modeled as random decision noise. Crucially, however, this deterministic source of variability is very much in the stimulus and if you saw the same friend go into the same restaurant at a later date you might follow them again. Conversely, truly `random' noise would arise from stochastic mental processes, 
	
	%tossing a metaphorical coin in your head. Such a process would not be influenced by the friend going into the restaurant, and if you saw the same friend again, you might make a different choice. 
	
	%A key limitation of our previous work was that the source of the decision noise used for exploration was left unknown.  In particular, due to the design of the task, we could not determine whether the adaptive decision noise that is linked to exploration arises deterministicly, in the input from the world, or is generated randomly, within the brain. 
	
	% The idea here is behavior is less predictable in horizon 6 than horizon 1 even when all stimuli are the same.  Thus anything that deterministically depends on stimuli - i.e. most modeling effects - are ruled out as an explanation for increased noise.  In that light, what your model calls deterministic noise is that amount of variance that could be explained by deterministic effects of stimulus - i.e. modeling errors.
	
	%* Difficulty with measuring random exploration, how do you know something is random, previous work model
	%* Model all the deterministic factor (contribute to noise)
	%* Have repeated games
	%* Missing deterministic dependent, much smaller than non-deterministic component
	%* Stochastic process… 
	
	%In the restaurant case, an example of deterministic noise would be if you happen to spot an old friend walking in to one of the restaurants. Such an event is random, in that you couldn't predict it, and has the potential to alter your behavior as you're likely to follow your friend in. Crucially, however, this `randomness' is very much in the world and if you saw the same friend go into the same restaurant at a later date you might follow them  again. 
	
	%Conversely, random noise would arise from stochastic neural processes tossing a metaphorical coin in your head. Such a process would not be influenced by the friend going into the restaurant, and if you saw the same friend again, you might make a different choice. 
	
	
	%Previous work makes a strong case for both deterministic and random noise being relevant to behavior. For instance, deterministic, stimulus-driven noise is thought to be a much greater source of choice variability in perceptual decisions than random noise \citep{eeBrunton13}. Conversely random, neural noise is thought to drive exploratory singing behavior in song birds and the generation and control of this random noise has been linked to specific neural structures \citep{songbird2}. 
	
	In this paper, we investigate the extent to which the apparent randomness in random exploration can be explained by such \added[id=siyu]{unobserved} deterministic processing of the stimulus \added[id=siyu]{(will refer to as deterministic noise)}. \replaced[id=siyu]{To distinguish between stimulus-driven `deterministic noise' and non-stimulus-driven `random noise'}{In particular}, we modify the Horizon Task \citep{wilson2014} to have people face the exact same explore-exploit choice twice. If the decision is a purely deterministic function of the stimulus \added[id=siyu]{(i.e., decision noise is purely deterministic noise)}, then people's choices should be identical both times. That is, their choices should be consistent, since the stimulus is the same both times. Conversely, the more their decision is driven by \replaced[id=siyu]{random noise}{other processes, including both stochastic and unobserved deterministic processes}, the less consistent their behavior should be. \added[id=siyu]{We built a computational model to quantify the relative magnitudes of stimulus-driven deterministic noise and non-stimulus-driven random noise in driving random exploration. Our model could detect the existence of previously unobserved deterministic processes without making a priori assumptions about the deterministic process that we want to observe.} By analyzing behavior on this task in both a model-free and model-based manner, we show that at least some of the `randomness' in random exploration must come from deterministic processing of the stimulus. \replaced[id=siyu]{Our work}{This does not prove that random exploration is entirely deterministic or stochastic, but} provides a lower bound on how much deterministic processes contribute to random exploration\added[id=siyu]{, and an upper bound on how much true random noises contribute to random exploration}. \deleted[id=siyu]{This in turn sheds light on how random exploration may be implemented by amplifying the effects of task-irrelevant stimuli on choice.}
	
	% SIYU says: "Conversely, the more their decision is driven by other processes, including both stochastic and unobserved deterministic processes, the less consistent their behavior should be. " is not correct. Unobserved deterministic processes will be the same for repeated games and will not contribute to choice inconsistency.
	
	%which source of noise, deterministic vs random, drives random exploration in humans in a modified version of the Horizon Task. To distinguish between the two types of noise, we had people make the exact same explore-exploit decision twice. If decision noise is purely deterministic noise, then people's choices should be identical both times, that is their choices should be consistent, since the stimulus is the same both times. Meanwhile, if decision noise is truly random their choices should be less consistent, since random noise can be different both times. By analyzing behavior on this task in both a model-free and model-based manner, we show that, while both types of noise are present in explore-exploit decisions, the variability related to random exploration is dominated by random noise. The missing deterministic component is much smaller than the non-deterministic component in random exploration.
	
	\section*{Results}
	
	\subsection*{The Repeated-Games Horizon Task}
	We used a modified version of the `Horizon Task' \citep{wilson2014} to show the influence of stimulus-driven `deterministic noise' vs non-stimulus-driven `random noise' \replaced[id=siyu]{in explore-exploit}{on people's} decisions (Figure \ref{fig:taskfig}). In this task, participants make repeated choices between two slot machines, or `one-armed bandits,' that pay out probabilistic rewards. Because they are initially unsure as to the mean payoff of each bandit, this task requires that participants carefully balance exploration of the lesser known bandit with exploitation of the better known bandit to maximize their overall rewards. 
	
	\begin{figure}[hp]
		\begin{center}
			\includegraphics[width=\textwidth]{figures/taskfiga.pdf}
			\caption{ 
				Schematic of the experiment. (A) Dynamics of an example horizon 6 game.  Here the first four trials are forced trials in which participants are instructed which option to play.  After the forced trials, participants are free to choose between the two options for the remainder of the game.  (B) Example repeated games over the course of the experiment.
				% Different possible states of the game after the first free choice over the course of the experiment. 
				On average, participants play more than 150 such games, with varying horizon (1 vs 6), uncertainty condition ([1 3] vs [2 2]) and observed rewards.  In addition, all games are repeated (as Game 18 and 100 are here) such that participants will be faced with the exact same pattern of forced trials and exact same outcomes from those forced trials twice within each experiment.  These repeated games allow us to compute the relative contribution of deterministic and random noise by analyzing the extent to which choices are {\em consistent} across the repeated games.}
			\label{fig:taskfig}
		\end{center}
	\end{figure}
	
	Crucially, before people make their first choice in the Horizon Task, they are given information about the mean payoff from each bandit in the form of four example plays distributed either unequally between bandits (i.e. 1 play of one bandit, 3 plays of the other, the [1 3] condition) or equally (2 plays each, the [2 2] condition). These example plays allow us to manipulate exactly what people know about each option before they make their first choice. 
	
	Relative to the original Horizon Task, the key modification here is to give people `repeated games,' in which they see exact same set of example plays twice in two separate games (separated by several minutes in time so as to avoid detection). By repeating the instructed plays for each game twice, we can set up a situation where (unbeknownst to the participants) they are faced with the exact same explore-exploit choice, with the exact same stimuli twice. Thus, if their behavior is a deterministic function of the stimuli, they will behave identically on the two games, that is their \replaced[id=siyu]{choices}{behavior} on the two versions of each game will be consistent. Conversely, if their behavior is not driven by a deterministic function of the stimulus, then their choices on the repeated games \replaced[id=siyu]{could}{should} be inconsistent. \replaced[id=siyu]{The extent to which participants' choices are consistent on the repeated versions of the games allow}{On average participants played 67.31 repeated games each allowing} us to quantify the extent to which \added[id=siyu]{the variability in} their behavior was \replaced[id=siyu]{driven by a deterministic process vs a random noise process}{a deterministic function of the stimulus or not}.
	
	%, the example plays allow us to probe how participants respond to the exact same explore-exploit choice twice.  
	
	%These `repeated games' are the key manipulation in this paper and allow us to distinguish between deterministic and random sources of noise.  Specifically, if noise is deterministicly driven, then choices on repeated games should be consistent. Conversely if noise is randomly driven, then choices on repeated games should be inconsistent.
	
	
	\subsection*{Both behavioral variability and information seeking increase with horizon}
	
	Before discussing the results for repeated games, we first confirm that the basic behavior in this task is consistent with our previously reported results \citep{wilson2014}. As in our previous work, we find evidence for two types of exploration in the Horizon Task: Random exploration, which is the main focus of this paper, where exploration is driven by noise, and directed exploration, where exploration is driven by information (Figure \ref{fig:modelfree}, Supplementary Figure S1). 
	
	Random exploration is quantified in a model-free way as the probability of choosing the low mean option, $p(\mbox{low mean})$ in the equal, or [2 2], condition. This value increases with horizon, consistent with the idea that behavior is more random in horizon 6 (t(64) = 6.55, p $<$ 0.001 for [1 3], t(64) = 7.99, p $<$ 0.001 for [2 2]).  Directed exploration, is measured as the probability of choosing the more informative option $p(\mbox{high info})$ in the unequal, or [1 3], condition. Again this measure increases with horizon, showing that people are more information seeking in horizon 6 (t(64) = 6.92, p $<$ 0.001).
	
	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=\textwidth]{figures/RanDetNoise_modelfree.jpg}
			\caption{
				Replication of previous findings. Both  $p(\mbox{low mean})$ (A) and $p(\mbox{high info})$ (B) increase with horizon suggesting that people use both random and directed exploration in this task.  }
			\label{fig:modelfree}
		\end{center}
	\end{figure}
	
	\subsection*{Model-free analysis shows that random exploration may involve both random and deterministic noise}
	
	Next we asked whether participants' choices were consistent or inconsistent in the two repetitions of each game. The idea behind this measure is that purely deterministic noise should lead to consistent choices as the deterministic stimulus is identical both times. \deleted[id=siyu]{Conversely, if choice is not a deterministic function of the stimulus, participants' choices should be independent, and hence more inconsistent across the repetitions of the game.}\added[id=siyu]{Conversely, if choice is not entirely driven by a deterministic process and is also driven by random noise, participants' choices should be more inconsistent across the repetitions of the game. Moreover, if decision noise is purely random noise, meaning there is no unobserved deterministic process, we will show that we can actually predict the expected level of choice inconsistencies across repetitions of games by accounting for the known deterministic processes and assuming that the random noise process is independent in repetitions of the game.}
	
	To quantify choice inconsistency we computed the frequency with which participants made different responses for pairs of repeated games (Figure \ref{fig:mf2}, Supplementary Figure S2). Using this measure we found that participants made inconsistent choices in both the unequal ([1 3]) and equal ([2 2]) information conditions, suggesting that not all of the noise was stimulus driven (t-test vs zero revealed that inconsistency was greater than zero for all horizon and uncertainty conditions\deleted[id=siyu]{For [1 3] condition, t(64) = 13.72, p $<$ 0.001 for horizon 1, t(64) = 16.71, p $<$ 0.001 for horizon 6; For [2 2] condition, t(64) = 9.55, p $<$ 0.001 for horizon 1, t(64) = 17.93, p $<$ 0.001 for horizon 6}). In addition, we found that choice inconsistency was higher in horizon 6 than in horizon 1 for both [1 3] and [2 2] condition (For [1 3] condition, t(64) = 5.41, p $<$ 0.001; for [2 2] condition, t(64) = 6.26, p $<$ 0.001), suggesting that at least some of the horizon dependent noise is not a deterministic function of the stimulus\added[id=siyu]{, but rather random noise}.
	
	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=\textwidth]{figures/RanDetNoise_pinconsistent.jpg}
			\caption{Model-free analysis suggests that both deterministic and random noise contribute to the choice variability in random exploration. For both the [1 3] (A) and [2 2] (B) condition, people show greater choice inconsistency in horizon 6 than horizon 1. However, the extent to which their choices are inconsistent lies between what is predicted by purely deterministic and random noise, suggesting that both noise sources influence the decision.}
			\label{fig:mf2}
		\end{center}
	\end{figure}
	
	To gain more quantitative insight into these results, we computed theoretical values for the choice inconsistency for the purely deterministic and purely random noise cases.  For purely deterministic noise this computation is simple because people should make the exact same decisions each time in repeated games, meaning that $p(\mbox{inconsistent}) = 0$ in this case. For purely random noise, the two games should be treated independently, allowing us to compute the choice inconsistency in terms of the probability of choosing the low mean option, $p(\mbox{low mean})$, as
	\begin{equation*}
		\begin{split}
			p(\mbox{consistent}) &= p(\mbox{low mean})^2 + p(\mbox{high mean})^2\\
			&= p(\mbox{low mean})^2 + (1-p(\mbox{low mean}))^2\\ 
			\mbox{hence},\quad p(\mbox{inconsistent}) &=  
			1 - p(\mbox{consistent}) = 
			2 p(\mbox{low mean})(1-p(\mbox{low mean}))
		\end{split}
	\end{equation*}
	\added[id=siyu]{Furthermore, to account for that $p(\mbox{low mean})$ is a function of reward difference $\Delta R$ between the two bandits and the information condition $I$, we estimated the conditional probability:
		$$p(\mbox{inconsistent}|\Delta R, I) = 2 p(\mbox{low mean}|\Delta R, I)(1-p(\mbox{low mean}|\Delta R, I))$$
		Then based on the likelihood that each condition ($\Delta R$ vs $I$) occurs in the task $\rho(\Delta R, I)$, we have
		$$p(\mbox{inconsistent}) = \sum_{\Delta R, I}\rho(\Delta R, I)p(\mbox{inconsistent}|\Delta R, I)$$}
	
	As shown in Figure \ref{fig:mf2}, people's behavior falls in between the pure deterministic noise prediction and the pure random noise prediction. Specifically, behavior is different from pure random noise prediction in the both the [1 3] condition (t(64) = 4.83, p $<$ 0.001 for horizon 1, t(64) = 3.12 p $=$ 0.003 for horizon 6) and the [2 2] condition (t(64) = 3.92, p $<$ 0.001 for horizon 1, t(64) = 3.71, p $<$ 0.001 for horizon 6). Likewise, behavior is different from pure deterministic noise prediction in both the [1 3] condition (t(64) = 13.72, p $<$ 0.001 for horizon 1, t(64) = 16.71, p $<$ 0.001 for horizon 6) and the [2 2] condition (t(64) = 9.55, p $<$ 0.001 for horizon 1, t(64) = 17.93, p $<$ 0.001 for horizon 6). \added[id=siyu]{As a negative control of our method for estimating $p(\mbox{inconsistent})$ for purely random noise, we simulated choices using a decision model that only includes random noise (for details, see the results section on model-based analysis, and methods), and found that $p(\mbox{inconsistent})$ in this simulated data is not different from our pure random noise prediction in all horizon and uncertainty conditions (p $>$ 0.05, Supplementary Figure S3).} \replaced[id=siyu]{Together, our results suggest that both random noise and deterministic noise contribute to the choice variability in random exploration.}{This suggests that at least some of the `noise' is a deterministic function of the stimulus, } Although from this analysis it is not clear whether this deterministic noise increases with horizon or not.
	
	\subsection*{Model-based analysis \replaced[id=siyu]{provides a lower-bound estimate of deterministic noise and an upper-bound estimate of random noise}{shows deterministic noise changes with horizon}}
	
	To more precisely quantify the contribution of deterministic noise \added[id=siyu]{and random noise}, we turned to model fitting. We modeled behavior on the first free choice of the Horizon Task using a version of the logistic choice model in \citep{wilson2014} that was modified to differentiate \replaced[id=siyu]{between components of the noise that are deterministically driven by the stimulus (`deterministic noise') and components of the noise that are not deterministically driven by the stimulus (`random noise')}{deterministic noise from random noise}. In particular, we assume that in repeated games, the value of stimulus-driven deterministic noise is frozen whereas random noise is drawn independently both times. 
	
	\subsubsection*{Overview of model}
	As with our model-free analysis, the model-based analysis focuses only on the first free-choice trial since that is the only free choice when we have control over the experience participants have about two bandits. To model participants' choices on this first free-choice trial, we assume that they make decisions by computing the difference in value $\Delta Q$ between the right and left options, choosing right when $\Delta Q > 0$ and left otherwise.  Specifically, we write
	\begin{equation}
		\Delta Q= \Delta R+A \Delta I+b+n_{det}+n_{ran}
	\end{equation}
	where, the experimentally controlled variables are $\Delta R=R_{right}-R_{left}$, the difference between the mean of rewards shown on the forced trials, and $\Delta I$, the difference \added[id=siyu]{of} information available for playing the two options on the first free-choice trial. For simplicity, and because information is manipulated categorically in the Horizon Task, we define $\Delta I$ to be +1 if one reward is drawn from the right option and three are drawn from the left in the [1 3] condition, -1 if one from the left and three from the right, and in [2 2] condition, $\Delta I$ is 0. \added[id=siyu]{$n_{det}$ denotes the deterministic noise, which is identical on the repeat versions of each game; and $n_{ran}$ denotes random noise, which is uncorrelated between repeated plays and changes every game.} $n_{det}$ and $n_{ran}$ are assumed to come from logistic distributions with mean 0\added[id=siyu]{, and standard deviations $\sigma_{det}$ and $\sigma_{ran}$}. The subject-and-condition-specific parameters are: the spatial bias, $b$, which determines the extent to which participants prefer the option on the right; the information bonus $A$, which controls the level of directed exploration; \added[id=siyu]{$\sigma_{det}$ and $\sigma_{ran}$, which control the respective level of deterministic noise and random noise in random exploration.}
	
	For each pair of repeated games, the set of forced-choice trials are exactly the same, so the deterministic noise, $n_{det}$, should be the same while the random noise, $n_{ran}$ may be different. This is exactly how we distinguish deterministic noise from random noise. In symbolic terms, for repeated games $i$ and $j$,  $n_{det}^i=n_{det}^j$  and $n_{ran}^i \neq n_{ran}^j$.
	
	We used hierarchical Bayesian analysis to fit the parameters of the model (see Figure \ref{fig:model} for an graphical representation of the model in the style of \cite{lee2014}). In particular, we fit values of the information bonus $A$, spatial bias $b$, variance of random noise $\sigma_{ran}^2$, and variance of deterministic noise, $\sigma_{det}^2$ for each participant in each horizon. Model fitting was performed using the MATJAGS and JAGS software \citep{jags, matjags} with full details given in the Methods.  
	
	\subsubsection*{\replaced[id=siyu]{Model validation}{Parameter recovery}\label{ch:appendix:bayesrecovery}}
	To be sure that our fit parameter values were meaningful \added[id=siyu]{and to understand the limits of our model, we evaluated our model in several ways. Firstly, we checked if our fitted deterministic noise could indeed capture unobserved deterministic process that was not accounted for by the decision model. We test this by leaving out one known deterministic process from the decision model, and ask if our method could recover that known deterministic process as deterministic noise. In particular, we fit a reduced version of our model that only considers reward and ignores the influence of uncertainty condition on explore-exploit decisions.  
		$$\Delta Q= \Delta R+n_{det}+n_{ran}$$
		Here, $\Delta Q, \Delta R, n_{det}, n_{ran}$ represent the same variables as in the full model.	If deterministic noise in our model can indeed capture unobserved deterministic processes that's missed by the model, then we would expect to see a higher level of fitted deterministic noise in the reduced model compared to in the full model, whereas the level of random noise should remain unchanged. By comparing the	fitted posterior distributions over the group-level means of the deterministic and random noise parameters $\sigma_{det}$ and $\sigma_{ran}$, as expected, we observed an increase in deterministic noise and no change in random noise between the reduced and the full model (Figure \ref{fig:reducedmodel}). This suggests that our model is capable of detecting missing deterministic processes.
	}
	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=0.7\textwidth]{figures/RDBayes_reduced_model.jpg}
			\caption{Deterministic noise can recover known deterministic processes that's intentionally omitted by the model. In the reduced model where the deterministic effect of uncertainty condition is omitted from the model, deterministic noise is higher compared to the full model that accounts for the effect of uncertainty. Random noise remains unchanged between the two models.}
			\label{fig:reducedmodel}
		\end{center}
	\end{figure} 
	
	\added[id=siyu]{Secondly, we evaluated our hierarchical Bayesian analysis procedure using the `frequentist coverage analysis'. In the coverage analysis, we simulated choices with the fitted parameters from the Hierarchical Bayesian analysis, and then re-fit the simulated choices to see whether we can recover the parameters (Figure \ref{fig:coverage2}, Supplementary Figure S4). The simulation and re-fitting was repeated for 200 times. Then we counted out of the 200 repetitions how many times the true parameter that we simulate the choices from lies in the fitted 95\% confidence interval. If our model fitting is reliable, then the fitted confidence interval should cover the true parameter for more than 95\% of the simulations (this ratio will be referred to as the coverage rate). For random noise, the coverage rate is 100\% for both horizon 1, horizon 6, and the horizon difference. For deterministic noise, the coverage rate is 66\% for horizon 1 and 69\% for horizon 6. By comparing the posterior distributions of parameters that were used to generate simulations and the posterior distribution of recovered parameters, it is clear that our model systematically underestimates deterministic noise (Figure \ref{fig:coverage2}). Despite the underestimation of deterministic noise in both horizons, we could still reliably detect the horizon changes of deterministic noise (coverage rate is 97\%). This is because the underestimation of deterministic noise is partially canceled out when the difference is taken between horizons. For random noise, our model fitting procedure yields a faithful recovery. However, there is a conceptual limitation. Because random noise is modeled as non-stimulus-driven noise, it can include both true stochastic neural noise and possible deterministic noises which do not depend on the stimuli. Because of this, our random noise estimate provides an upper bound of true `random noise' induced by intrinsic stochastic processes in the brain.}
	
	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=1\textwidth]{figures/RDBayes_parameterrecovery_hyperprior_v2.jpg}
			\caption{Parameter recovery over the posterior distribution of random and deterministic noise standard deviations $\sigma_{det}$ and $\sigma_{ran}$. Solid lines are true posterior used to simulate choices. Lighter color shades represent the re-fitted posterior to the simulated choices. Our model fitting procedure faithfully recovers the non-stimulus-driven random noise (A, B), but systematically underestimates deterministic noise in both horizons (D, E). The horizon differences in random noise is also faithfully recovered (C). The horizon differences in deterministic noise is also underestimated but not significant (F).}
			\label{fig:coverage2}
		\end{center}
	\end{figure} 
	
	\added[id=siyu]{Next, we tested the ability of our model fitting procedure to recovery parameters from simulated data at the subject level (Supplementary Figure S5 and S6). The correlations between the true vs fitted parameters are significant across participants for all parameters (p $<$ 0.001). The strength of correlation between simulated and fit values are strong for both deterministic noise (R $>$ 0.8) and random noise (R $>$ 0.9). Despite the strong inter-subject correlations, we again observed a systematic underestimation of $\sigma_{det}$ (Supplementary Figure S5 and S6).}
	
	%Parameter recovery is good (in terms of) for all parameters apart from the bias in short horizon condition, which is likely due to this parameter being so close to zero (Figure \ref{fig:pararecover1} Panel C). The recovery for the noise parameters, $\sigma_{det}$ and $\sigma_{ran}$, is slightly better for horizon 1 than horizon 6.
	
	\added[id=siyu]{Lastly, in addition to testing how our model performs in parameter ranges around the actual fitted parameters, we tested the limitations of our models in arbitrary combinations of random vs deterministic noises. All combinations of random and deterministic noises with $0 \le \sigma_{det} \le 10$ and $0 \le \sigma_{ran} \le 10$ were tested. In a special case, we evaluated how our model performs when there is only random noise or only deterministic noise (Figure \ref{fig:puredetran}). In the simulation with fully deterministic noise and 0 random noise, our model successfully recovered both random and deterministic noise (Figure \ref{fig:puredetran} C, D), however in the simulation with fully random noise and 0 deterministic noise, although our model successfully recovered random noise, some small proportion of deterministic noise was falsely detected when they should instead be 0 (Figure \ref{fig:puredetran} A, B). However, this phenomenon only exists when the true deterministic noise is 0, once the true deterministic noise is greater than 1, we don't observe this inflation of deterministic noise anymore (Supplementary Figures S7). Apart from this, our model did a fairly good job in recovering all combinations of random and deterministic noises (Supplementary Figures S7).}
	
	%Overall, we see better recovery for random noise than deterministic noise. This is likely because we effectively have half as many trials for deterministic noise. In particular, while we generate two samples of random noise for each repeated game pair, we only generate one sample of deterministic noise, which by definition is the same in both of the repeated games.
	
	%This is because it requires more trials to recover larger values of $\sigma_{det}$ and $\sigma_{ran}$, so with the same number of choices it is harder to recover overall larger noise variances in horizon 6. 
	
	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=0.7\textwidth]{figures/RDBayes_parameterrecovery_grid_pureRanDet.jpg}
			\caption{Parameter recovery over the posterior of random noise standard deviation, $\sigma_{ran}$, and deterministic noise standard deviation, $\sigma_{det}$, for purely random noise (top row) and purely deterministic noise (bottom row) games. 
			}
			\label{fig:puredetran}
		\end{center}
	\end{figure} 
	% Thus, our model provides a lower bound on deterministic noise and an upper bound on random noise.
	
	\added[id=siyu]{Overall, we are able to detect both deterministic and random noises using our model to a satisfactory extent. Our model provides a lower bound for deterministic noise and an upper bound for random noise. In addition, We see better parameter recovery for random noise than deterministic noise. This is likely because we effectively have half as many trials for deterministic noise. In particular, while we generate two samples of random noise for each repeated game pair, we only generate one sample of deterministic noise, which by definition is the same in both of the repeated games. 
	}
	\subsubsection*{Model-based results} 
	
	Posterior distributions over the group-level means of the deterministic and random noise standard deviation $\sigma_{det}$ and $\sigma_{ran}$ are shown in Figure \ref{fig:mb1} and Supplementary Figure S8. Consistent with our model-free results, we see that both random and deterministic noise are non-zero. \replaced[id=siyu]{Numerically,}{and that} random noise is about 2-3 times larger than the deterministic noise. \added[id=siyu]{By computing the posterior distribution of $\sigma^2_{det}/(\sigma^2_{det}+\sigma^2_{ran})$, our data suggests that 14.25\% of the variability in random exploration is accounted for by deterministic noise ([4.90\%, 28.81\%], 95\% CI).} In addition, we find that both random and deterministic noise increase with horizon. This increase was larger for random noise (mean = 7.13, 100\% of samples showed an increase in random noise with horizon) than deterministic noise (mean = 2.59, 98.64\% of samples showed an increase in deterministic noise with horizon). But intriguingly, the relative increase in both types of noise was \replaced[id=siyu]{similar}{the same} (Figure \ref{fig:ratio}). That is when we compute the relative increase in deterministic noise with horizon, $\sigma^{det}_{horizon6}/\sigma^{det}_{horizon1}$, it is \replaced[id=siyu]{very similar}{almost identical} to the relative increase in random noise with horizon $\sigma^{ran}_{horizon6}/\sigma^{ran}_{horizon1}$. 
	%BOB SAYS: CHECK NOTATION HERE AND INSERT FIGURE SHOWING RATIO  
	
	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=0.7\textwidth]{figures/RDBayes_hyperprior.jpg}
			\caption{Model based analysis showing the posterior distributions over the group-level mean of the standard deviations of  random and deterministic noise. Both random (A, B) and deterministic (C,D) noises are nonzero (A, C) and change with horizon (B, D).  However, random noise has both a greater magnitude overall (A, C) and a greater change with horizon (B, D) than deterministic noise.}
			%BOB SAYS: DON'T NEED THE NUMBERS ON THE Y-AXES. 
			\label{fig:mb1}
		\end{center}
	\end{figure}
	
	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=0.5\textwidth]{figures/RDBayes_ratio__paironly.jpg}
			\caption{Model based analysis showing the posterior distributions over the ratio of the group-level mean of the standard deviations of  random and deterministic noise between horizon 6 and horizon 1 respectivelly. The ratio in the standard deviations of noise between horizon 6 and horizon 1 is similar for random and deterministic noise.}
			\label{fig:ratio}
		\end{center}
	\end{figure}
	
	\subsubsection*{Posterior predictive checks}
	In addition to fitting the model to behavior, it is also important to check whether the model captures the qualitative patterns of the data \citep{Wilson2019} --- specifically how p(high info), p(low mean) and p(inconsistent) change with horizon.
	
	To perform this `posterior predictive check,' we created a set of simulated data by taking the subject-level parameters from the hierarchical Bayesian fits and having the model play the same sequence of games as seen by the subjects. We then applied the same model-free analysis as described in the previous sections to this simulated data set and compared the model's behavior to that of participants. As shown in Figure  \ref{fig:mb3}, the model can account for all qualitative patterns in the data --- the increase in p(high info), p(low mean), and p(inconsistent) with horizon, and that p(inconsistent) is in between pure random and pure deterministic noise.  The quantitative agreement is almost perfect for p(high info) and for p(inconsistent) in the [1 3] condition, but the model seems to systematically overestimate p(low mean) and p(inconsistent) in [2 2] conditions, although the discrepancy is relatively small (overestimating p(low mean) by 0.054 or 31.37\%, and p(inconsistent) by 0.049 or 27.83\% in [2 2] condition).
	
	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=1\textwidth]{figures/RDBayes_2noise_modelA.jpg}
			\caption{
				% BOB SAYS: KEEP THE TOP LINE OF THIS FIGURE FOR THE MAIN PAPER AND MOVE THE FULL FIGURE TO SUPPLEMENTARY MATERIAL TO FIT DESCRIPTION IN TEXT.  
				% ALSO MAKE THE FOLLOWING CHANGES: THIS FIGURE NEEDS A LEGEND IN TOP RIGHT TO SAY WHICH LINE IS MODEL AND WHICH IS NOT.  I WOULD ALSO USE TEXTBOXES (in Matlab annotation('textbox', [0 0 1 1], 'string', 'hi') will get you started) TO DESCRIBE THE MODELS RATHER THAN LABELLING MODEL A ETC ... COULD EVEN HAVE SOME FORM OF TABLE 1 ON THE LEFT HAND SIDE - SO A COLUMN FOR DETERMINISTIC NOISE AND A COLUMN FOR RANDOM NOISE.
				Our model accounts for all qualitative patterns of the data, namely, p(high info) and p(low mean) increase as a function of horizon, p(inconsistent) increases as a function of horizon for both [1 3] and [2 2] conditions and lies between the pure random and pure deterministic noise prediction.}
			\label{fig:mb3}
		\end{center}
	\end{figure}
	
	\subsubsection*{Comparison with alternative models}
	To check whether all aspects of the model were necessary to reproduce the qualitative pattern of findings, we also built and fit five additional versions of the model. These models varied \added[id=siyu]{in} whether deterministic and random noise are present or not and whether either types of noise is dependent on horizon. \added[id=siyu]{Specifically, we tested the following 6 models (Note that the $\sigma^{ran}_{horizon},\sigma^{det}_{horizon}$ model is our original full model).}
	
	\begin{table}[h]
		\small
		\centering
		\begin{tabular}{|c|c|c|}
			\hline
			Model & Deterministic noise & Random noise \\
			\hline
			$\sigma^{ran}_{horizon},\sigma^{det}_{horizon}$  & Horizon dependent & Horizon dependent\\
			\hline
			$\sigma^{ran}_{horizon},\sigma^{det}_{}$ & Fixed & Horizon dependent\\
			\hline
			$\sigma^{ran}_{},\sigma^{det}_{horizon}$ & Horizon dependent & Fixed\\
			\hline
			$\sigma^{ran}_{},\sigma^{det}_{}$ & Fixed & Fixed\\
			\hline
			$\sigma^{ran}_{horizon}$ & Horizon dependent & None\\
			\hline
			$\sigma^{det}_{horizon}$ & None & Horizon dependent\\
			\hline
		\end{tabular}
		\caption{Variants of the model.}
		\label{tab:models}	
	\end{table}
	\added[id=siyu]{
		The posterior distributions over the group-level means of the deterministic and random noise standard deviation $\sigma_{det}$ and $\sigma_{ran}$ (when they exist) in these model variants are shown in Supplementary Figure S9. We again simulated choices using fitted parameters from these models and repeated the model-free analysis on the simulated data. 
	}As shown in Supplementary Figure S10, only one of these models, where random noise is horizon dependent but deterministic noise is not, can capture the full qualitative pattern of \replaced[id=siyu]{behavior}{responding}. However, the quantitative fit to the data is not as good (Supplementary Figure S10).% SIYU says: they actually look quite similar, without horizon dependent deterministic noise, the fixed det noise model is only marginally worse on p(inconsistent) in [2 2] condition, as it overlaps with the pure random noise line more.
	
	\added[id=siyu]{
		Moreover, we examined if our model can indeed qualitatively capture whether deterministic and random noise are present or not and whether either types of noise is dependent on horizon. To test this, we simulated choices from each of the 6 models, and then fit the simulated choices with our original full model. The simulation was repeated 50 times for each model. Indeed, we showed that our model can capture both the existence of random and deterministic noise, and whether each noise changes with horizon condition (Figure \ref{fig:6model}), with only one exception that our model falsely detected a small fraction of deterministic noise when no deterministic noise was present (Figure \ref{fig:6model}, S). This phenomenon was also examined and discussed in the section "Model validation" above.
	}
	
	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=0.8\textwidth]{figures/RDBayes_2noise_hyperprior_6model_recovery.jpg}
			\caption{
				Our model qualitatively captures whether deterministic and random noise are present or not and whether either types of noise is dependent on horizon. A-D. both deterministic and random noise are horizon dependent, E-H. only random noise is horizon dependent, I-L. only deterministic noise is horizon dependent, M-P. neither random nor deterministic noise is horizon dependent, Q-T. only deterministic noise is assumed to be present, U-X. only random noise is assumed to be present.}
			\label{fig:6model}
		\end{center}
	\end{figure}
	
	
	
	%The previous section suggests that behavioral variability in random exploration can be at least partially explained by deterministic processing of the stimulus. 
	
	%dominated by random noise. To test this more explicitly, we build a series of models in which different assumptions are made regarding the presence and absence of both types of noise and whether each type of noise if exists is horizon dependent (See Table \ref{tab:models}). In model A-D, we assumed the existence of both random and deterministic noise, in model A and B, random noise is assumed to be horizon-dependent, whereas in model A and C, deterministic noise is assumed to be horizon dependent. In model E, we assumed no random noise. In model F, we assumed no deterministic noise. 
	
	%To evaluate and compare between models, we simulated choice behavior by taking the subject-level parameters from the Hierarchical Bayesian fits. The same model-free analysis as described in the previous session is applied to all 6 sets of simulated data for the 6 models respectively. (See Figure  \ref{fig:mb3}). 
	
	%The original measure of random exploration, p(low mean), as used in \cite{wilson2014} can be explained by having deterministic noise alone (Figure \ref{fig:mb3}, Panel E2) or having random noise alone (Figure \ref{fig:mb3}, Panel F2). That participants qualitatively exploit the high-mean option less and choose the low-mean option more in horizon 6, can be explained by having both pure deterministic noise and pure random noise, as long as noise is horizon dependent. If both deterministic and random noise are assumed to be the same for both horizons (Figure \ref{fig:mb3}, Panel D), p(low mean) becomes completely flat and no horizon dependent random exploration is observed.
	
	%On the other hand, by looking at the percentage of inconsistent choices in the repeated pair of game, p(inconsistent), external noise alone can not account for behavior any more (Figure \ref{fig:mb3}, Panel E3, E4). Moreover, model C and D are disqualified that the increase of choice inconsistency with horizon can only be qualitatively accounted for when random noise is horizon-dependent (Figure \ref{fig:mb3}, Panel A, B, F).
	
	%Among the models A, B and F, where random noise is horizon dependent, model A provides the best quantitative fit. If there is no deterministic noise (Model F), then we overestimate the level of choice inconsistency in both horizons by a constant. In addition, horizon dependent deterministic noise gives slightly better model fits than if deterministic noise is assumed to be the same in both horizons. Overall, these model simulations confirmed that the horizon dependence of random noise is the main source of random exploration.
	
	
	\section*{Discussion}
	
	
	
	% BOB SAYS: CAN YOU TRY TO REFRAME THIS AROUND THE DETERMINISTIC STORY
	\added[id=siyu]{Randomness in exploratory behavior can be driven by both the intrinsic variability generated in the brain (show up in behavior as random noise) and by deterministic neural processes induced by the stimuli (show up in behavior as deterministic noise).} In this paper, we investigated whether random exploration is really random or whether it is driven deterministically by aspects of the stimulus we have previously ignored when measuring `decision noise'.  Using a version of the Horizon Task with repeated games, we found evidence that at least some of the noise in random exploration could be explained by such `deterministic noise.' In particular, we found that deterministic noise accounted for around 15\% of the overall variability in people's behavior. 
	
	%	\added[id=siyu]{We quantified the contribution of both deterministic noise (unobserved deterministic processes of the stimulus) and random noise (intrinsic stochasticity in decision making, or stimulus irrelevant processes) contribute to behavioral variability in random exploration, 
		
		So where does this leave randomness in random exploration? \replaced[id=siyu]{In our model, random noise is modeled as non-stimulus-driven variability, which may include truly random noise (intrinsic stochasticity in decision making) or stimulus irrelevant deterministic processes that we could not control in the lab. As a result,}{Well, } the remaining 85\% of the decision noise could be random or it could be deterministic \replaced[id=siyu]{processes that is not bound to the stimulus and that we can not control}{because we can't control everything}. In particular, while we controlled many aspects of the stimulus across repeated games (e.g. the outcomes and the order of the forced trials), we could not perfectly control {\it all} stimuli the participant received, which would vary, for example, based on exactly what they were looking at or whether they were fidgeting or scratching their nose \citep{Musall2019}. Thus conceptually, our estimate of random noise is an upper bound as these `missing' sources of deterministic noise would be interpreted as random noise in our model. Conversely, our estimate of deterministic noise is a lower bound. \added[id=siyu]{Future work is needed to identify these additional sources of deterministic noise that are not controlled in our work, for example by tracking people's pose, body movements and eye movements during the experiment.}
		
		In addition to the conceptual limitation in measuring deterministic noise, parameter recovery simulations suggest that our estimation method also systematically underestimates deterministic noise (see Figure \ref{fig:coverage2}, Supplementary Figure S6). From both a conceptual and methodological perspective, our model provides a lower bound of deterministic noise and an upper bound of random noise. Although there is still a considerable window for truly stochastic processes in the brain to be driving random exploration (up to 85\%), our results suggest that at least some of the apparent randomness in random exploration is not random at all. 
		
		\added[id=siyu]{The deterministic noise hypothesis is in line with works in which neural variability can be accounted for by fluctuations in sensory inputs. For example, }MT neurons were shown to have a reproducible temporal modulation in response to a fixed random motion stimuli \citep{Bair1996}. In other words, irrelevant features in the stimuli are represented in a reliable way in the brain that could drive downstream choices in a predictable way. Of particular interest was the fact that deterministic noise in our study increased with horizon, which is a hallmark of an exploratory process and suggests that the modulation of deterministic processes may underlie random exploration. 
		
		\added[id=siyu]{The random noise hypothesis, on the other hand, is consistent with findings of \cite{drugowitsch16}.} In particular these authors show that randomness in behavior could arise from imperfections in mental inference, which happen inside the brain, rather than in peripheral processes such as sensory processing and response selection. This suggests that a large proportion of variability in behavior may arise from computational errors in computing the correct strategy. \added[id=siyu]{Although suboptimal inference is different from simply adding random noise to a neural circuitry\citep{Pouget12}, as long as the suboptimality in neural computation is not deterministically determined by the stimuli, it is a form of random noise in our definition. }In the context of the Horizon Task, such computational errors would likely be larger in the long horizon condition as the correct course of action in these cases is much harder to compute.	
		%SIYU says the song bird literature supports that behavioral variability is reflected in neural variability. But it can't tell whether the neural variability arises from deterministic processes of external stimuli or random noise. I didn't read/remember the songbird paper, this is only based on the text below.
		%"The idea that random exploration is driven by truly stochastic processes in the brain is in line with work in the bird song literature in which variability during song learning has been tied to neural variability arising from specific areas of the brain \citep{songbird1, songbird2}" 
		
		
		%this is consistent with findings of \cite{drugowitsch16}. In particular these authors show that randomness in behavior arises from imperfections in mental inference, that happen inside the brain, rather than in peripheral processes such as sensory processing and response selection. This suggests that a large proportion of noise in behavior is generated randomly and that this may arise from computational errors in computing the correct strategy. % In the context of the Horizon Task, such computational errors would likely be larger in the long horizon condition as the correct course of action in these cases is much harder to compute.	
		
		%In the context of the Horizon Task, such computational errors would likely be larger in the long horizon condition as the correct course of action in these cases is much harder to compute.
		
		%Taken at face value, the horizon-dependent increase in random noise is consistent with the idea that random exploration is driven by intrinsic variability in the brain. 
		\added[id=siyu]{
			Regardless of whether the remaining 85\% is deterministic or random, the fact that the horizon change in the two noises are proportional to each other (Figure \ref{fig:ratio}) suggests a possible mechanism for random exploration. Specifically, a reduction in the strength with which reward drives the choice. In our decision model, choice is determined by the sign of the difference in utility $\Delta Q$ between the two options, thus, the absolute value of different terms in the model do not matter, $\Delta Q$ is only affected by the relative magnitude of reward, information, bias and noise. Mathematically, our model is equivalent to
		}
		\begin{equation*}
			\begin{split}
				\Delta Q' &= \beta \Delta Q \\
				&= \beta \Delta R + \beta A \Delta I + \beta b + \beta n_{det} + \beta n_{ran}\\
				&= \beta \Delta R + A' \Delta I + b' + n_{det}' + n_{ran}'
			\end{split}
		\end{equation*}
		\added[id=siyu]{In this equivalent form, $\beta$ determines the weight given to the reward in the decision. From a model fitting perspective, these two forms are equivalent. A decrease in $\beta$ here would be equivalent to an increase in variance of both deterministic and random noise. From a psychological perspective, however, they are quite different. An increase in both random and deterministic noise at a similar ratio relative to the reward, as observed in our experiment when horizon increases, suggests that either $\beta$ is reduced or $n_{det}'$ and $n_{ran}'$ are increased simultaneously at the same ratio. Neurally, reducing the $\beta$ corresponds to a reduction in reward sensitivity and reward coding, whereas simultaneously increasing $n_{det}'$ and $n_{ran}'$ suggests a common noise gating mechanism in which the noise filtering neural circuit is inhibited so that both random and deterministic noises are amplified. }
		%SIYU says the Ebitz paper sounds like choice signal is reduced during exploration, and p(switch|reward outcome) increases behaviorally in exploration state compared to exploitation? I am not sure it supported reward reduction?
		%Such reduced coding of reward would be consistent with \cite{ebitz17}.%In a recent report from \cite{ebitz17}, the behavioral variability of monkeys in an `explore' state was also tied to random rather than deterministic sources of noise. 
		
		Whether such a noise-controlling area exists in the human brain is less well established, but one candidate theory \citep{aj2005} suggests that norepinephrine (NE) from the locus coeruleus may play a role in modulating random levels of noise. Indeed, changes in the NE system have been associated with changes behavioral variability in both humans and other animals in a variety of tasks \citep{eeKarpova14, eeKeung18}.  In addition there is some evidence that NE plays a direct role in random exploration \citep{eeWarren17}, although this finding is complicated by other work showing no effect of NE drugs on exploration \citep{jepma2012, nieuwenhuis05}. 
		
		
		%On the other hand, our result suggests that at least one fifth of the decision noise in random exploration arises from a deterministic process. 
		
		%In our study, most of the decision noise seen can still be random noise (up to 72.95\%), and this is consistent with findings of \cite{drugowitsch16}. In particular these authors show that randomness in behavior arises from imperfections in mental inference, that happen inside the brain, rather than in peripheral processes such as sensory processing and response selection. This suggests that a large proportion of noise in behavior is generated randomly and that this may arise from computational errors in computing the correct strategy. % In the context of the Horizon Task, such computational errors would likely be larger in the long horizon condition as the correct course of action in these cases is much harder to compute.	
		
		%And you can change the relative contribution of noise by changing $\beta$.
		
		
		
		%In particular, in our analysis we excluded a scalar on $\Delta R$, if we include that then we get
		
		%To see this, we need to return to our equation for the computation of value
		%\begin{equation}
		%	\Delta Q = \Delta R + A \Delta I + b + n_{det} + n_{ran}
		%\end{equation}
		%In this version of the equation, the difference in value is a weighted of sum of reward, information, bias, deterministic noise,  and random noise.  Crucially, we assumed that the weighting given to the difference in reward is 1 --- that is the multiplier on $\Delta R$ is 1, unlike the variable $A$ which modulates the effect of information.  
		%A more general form of this equation would also include a scalar on $\Delta R$
		
		%REGARDLESS OF WHETHER THE REMAINING 75\% IS RANDOM OR NOT, THE FACT THAT THE HORIZON CHANGE IN THE TWO NOISES ARE PROPORTIONAL TO EACH OTHER SUGGESTS A POSSIBLE MECHANISM FOR RANDOM EXPLORATION.  SPECIFICALLY, A REDUCTION IN THE STRENGTH WITH WHICH REWARD DRIVES THE CHOICE.  IN PARTICULAR, IN OUR ANALYSIS WE EXCLUDED A SCALAR ON $\Delta R$.  IF WE INCLUDE THAT THEN WE GET
		%\begin{equation}
		%	\Delta Q = \beta \Delta R + A \Delta I + b + n_{det} + n_{ran}
		%\end{equation}
		%In this equation, $\beta$ determines the weight given to the reward in the decision.  From a model fitting perspective, these two forms are EQUIVALENT. From a psychological perspective they are quite different.  And you can change the relative contribution of noise by changing $\beta$.
		
		%	A decrease in $beta$ here would be equivalent to an increase in variance of both deterministic and random noise. Such reduced coding of reward would be consistent with \cite{ebitz17}.
		%A DECREASE IN $\beta$ HERE WOULD BE EQUIVALENT TO AN INCREASE IN VARIANCE OF BOTH DETERMINISTIC AND RANDOM NOISE.  MAKES THE PREDICTION THAT SPATIAL BIAS SHOULD ALSO CHANGE IN PROPORTION (CHECK THIS!).
		
		%SUCH REDUCED CODING OF REWARD WOULD BE CONSISTENT WITH EBITZ (I THINK).
		
		%Randomness in exploratory behavior in random exploration can be driven by both the intrinsic variability generated in the brain (show up in behavior as random noise) and by deterministic neural processes induced by the stimuli (show up in behavior as deterministic noise).  The idea that random exploration is driven by truly stochastic processes in the brain is in line with work in the bird song literature in which variability during song learning has been tied to neural variability arising from specific areas of the brain \citep{songbird1, songbird2}. In a recent report from \cite{ebitz17}, the behavioral variability of monkeys in an `explore' state was also tied to random rather than deterministic sources of noise. In our study, most of the decision noise seen can still be random noise (up to 72.95\%), and this is consistent with findings of \cite{drugowitsch16}. In particular these authors show that randomness in behavior arises from imperfections in mental inference, that happen inside the brain, rather than in peripheral processes such as sensory processing and response selection. This suggests that a large proportion of noise in behavior is generated randomly and that this may arise from computational errors in computing the correct strategy. % In the context of the Horizon Task, such computational errors would likely be larger in the long horizon condition as the correct course of action in these cases is much harder to compute.
		
		%Whether such a noise-controlling area exists in the human brain is less well established, but one candidate theory \citep{aj2005} suggests that norepinephrine (NE) from the locus coeruleus may play a role in modulating random levels of noise. Indeed, changes in the NE system have been associated with changes behavioral variability in both humans and other animals in a variety of tasks \citep{eeKarpova14, eeKeung18}.  In addition there is some evidence that NE plays a direct role in random exploration \citep{eeWarren17}, although this finding is complicated by other work showing no effect of NE drugs on exploration \citep{jepma2012, nieuwenhuis05}. 
		
		%On the other hand, our result suggests that at least one fifth of the decision noise in random exploration arises from a deterministic process. This is in line with works of \citep{Bair1996} in which MT neurons were shown to have a reproducible temporal modulation in response to a fixed random motion stimuli. In other words, irrelevant features in the stimuli are represented in a reliable way in the brain that could drive downstream choices in a predictable way. Of particular interest was the fact that deterministic noise in our study increased with horizon, which is a hallmark of an exploratory process and suggests that the modulation of deterministic processes may underlie random exploration.  
		
		%One way in which this may be achieved is if random exploration is modulated, not by increasing noise, but by decreasing reward sensitivity.  For example, modifying equation XXX to include a reward sensitivity term we get ...
		
		%Given that there is still a considerable window for truly stochastic processes in the brain to be driving random exploration, 
		
		
		%Despite this, it seems hard to imagine that these additional noise sources could be enough to account for the large differences between random and deterministic noise that we found in Figure \ref{fig:mb1}, where random noise is 2-3 times the size of deterministic noise.  
		
		
		
		
		\section*{Materials and Methods}
		\subsection*{Participants}
		
		80 participants (ages 18-25, 37 male, 43 female) from the University of Arizona undergraduate subject pool participated in the experiment. 14 were excluded on the basis of performance, using the same exclusion criterion as in \citep{wilson2014}. In this exclusion criteria, we measured the accuracy of each participant's choices by calculating the percentage of times that a participant chose the bandit with the higher underlying mean payouts in the last choice of a long horizon game, intuitively people should figure out which bandit has a higher mean payout by the last trial and should have an accuracy measure significantly above 50\%, specifically, we computed the likelihood that the measured accuracy can be achieved \deleted[id=siyu]{driven}by making a completely random choice between the two options and excluded participants with a likelihood smaller than 99.999\%, in other words, participants who didn't show an accuracy significant above chance with $p < 0.001$ were excluded in the analysis. This left 65 for the main analysis. Note that including the 15 badly performing subjects did not change the main results (Supplementary Figures 1 - 3)% MAKE AND INCLUDE REPLICAS OF ALL FIGS BUT WITH ALL SUBJECTS
		
		\subsection*{Task}
		The task was a modified version of the Horizon Task \citep{wilson2014} (Figure \ref{fig:taskfig}). In this task, participants play a set of games in which they make choices between two slot machines (one-armed bandits) that pay out rewards from different Gaussian distributions. In each game they made multiple decisions between two options. Each option paid out a random reward between 1 and 100 points sampled from a Gaussian distribution. The means of the underlying Gaussians were different for the two bandit options, remained the same within a game, but changed with each new game. One of the bandits always had a higher mean than the other. Participants were instructed to maximize the points earned over the entire task. To maximize their rewards in each game, participants need to exploit the slot machine with the highest mean, but they cannot identify this best option without exploring both options first. 
		
		The number of games participants played depended on how well they performed, which acted as the primary incentive for performing the task. Thus, the better participants performed, the sooner they got to leave the experiment. On average, participants played 153.7 games (minimum = 90 games, maximum = 192 games) and the whole task lasted between 12.37 and 32.15 minutes (mean 22.78 minutes). Participants played an average of 65.3 repeated pairs of games (minimum = 30 repeated pairs, maximum =  79 repeated pairs).
		%BOB SAYS: ADD HOW MANY REPEATED GAMES THEY PLAYED - GIVE A MEAN AND RANGE FOR THIS NUMBER
		
		As in the original paper \citep{wilson2014}, the distributions of payoffs tied to bandits were independent between games and drawn from a Gaussian distribution with variable means and fixed standard deviation of 8 points. Differences between the mean payouts of the two slot machines were set to either 4, 8, 12 or 20. One of the means was always equal to either 40 or 60 and the second was set accordingly. Participants were informed that in every game one of the bandits always has a higher mean reward than the other. The order of games was randomized. Mean sizes and order of presentation were counterbalanced. 
		
		Each game consisted of 5 or 10 choices. Every game started with a fixation cross, then a bar of boxes appeared indicating the horizon for that game. For the first 4 trials - the instructed trials, we highlight the box on one of the bandits to instruct the participant to choose that option. On these trials, they have to press the corresponding key to reveal the outcome. From the fifth trial, boxes on both bandits will be highlighted and they are free to make their own decision. There was no time limit for decisions. During free choices participants could press either the left arrow key or right arrow key to indicate their choice of left or right bandit. The score feedback was presented for 300ms. The task was programmed using Psychtoolbox in MATLAB \citep{psychtoolbox1, psychtoolbox2}. 
		
		The first four trials of each game were forced-choice trials, in which only one of the options was available for the participant to choose. We used these forced-choice instructed trials to manipulate the relative ambiguity of the two options, by providing the participant with different amounts of information about each bandit before their first free choice. The four forced-choice trials set up two uncertainty conditions: unequal uncertainty(or [1 3]) in which one option was forced to be played once and the other three times, and equal uncertainty(or [2 2]) in which each option was forced to be played twice. After the forced-choice trials, participants made either 1 or 6 free choices (two horizon conditions),  Figure \ref{fig:taskfig}.
		
		\subsection*{Model-based analysis}
		We modeled behavior on the first free choice of the Horizon Task using a version of the logistic choice model in \citep{wilson2014} that was modified to differentiate \replaced[id=siyu]{deterministic noise from random noise.}{between components of the noise that are deterministically driven by the stimulus (`deterministic noise') and components of the noise that are not deterministically driven by the stimulus (`random noise').}Because the stimuli are identical in the repeated games, by definition, deterministic noise remains the same in repeated games, whereas random noise can change. 
		
		\subsubsection*{Hierarchical Bayesian Model}
		
		To model participants' choices on this first free-choice trial, we assume that they make decisions by computing the difference in value $\Delta Q$ between the right and left options, choosing right when $\Delta Q > 0$ and left otherwise.  Specifically, we write
		\begin{equation}
			\Delta Q= \Delta R+A \Delta I+b+n_{det}+n_{ran}
		\end{equation}
		where, the experimentally controlled variables are $\Delta R=R_{right}-R_{left}$, the difference between the mean of the rewards shown on the forced trials, and $\Delta I$, the difference of information available for playing the two options on the first free-choice trial. For simplicity, and because information is manipulated categorically in the Horizon Task, we define $\Delta I$ to be +1, -1 or 0, +1 if one reward is drawn from the right option and three are drawn from the left in the [1 3] condition, -1 if one from the left and three from the right, and in [2 2] condition, $\Delta I$ is 0. The other variables are: the spatial bias, $b$, which determines the extent to which participants prefer the option on the right; the information bonus $A$, which controls the level of directed exploration; $n_{det}$ and $n_{ran}$ are deterministic noise and random noise respectively. $n_{det}$ denotes the deterministic noise, which is identical on the repeat versions of each game; and $n_{ran}$ denotes random noise, which is uncorrelated between repeat plays and changes every game.
		
		Each subject's behavior in each horizon condition is described by 4 free parameters (Table \ref{tab:pars2}): the information bonus $A$, the spatial bias, $b$, the standard deviation of the deterministic noise, $\sigma_{det}$, and the standard deviation of the random noise, $\sigma_{ran}$. Each of the free parameters is fit to the behavior of each subject using a hierarchical Bayesian approach \citep{hbm1}.  In this approach to model fitting, each parameter for each subject is assumed to be sampled from a group-level prior distribution whose parameters, the so-called `hyperparameters', are estimated using a Markov Chain Monte Carlo (MCMC) sampling procedure (Figure \ref{fig:model}). The hyper-parameters themselves are assumed to be sampled from `hyperprior' distributions whose parameters are defined such that these hyperpriors are broad.  
		
		The particular priors and hyperpriors for each parameter are shown in Table \ref{tab:pars2}. For example, we assume that the information bonus, $A^{is}$, for each horizon condition $i$ and for each participant $s$, is sampled from a Gaussian prior with mean $\mu^{A}_{i}$ and standard deviation $\sigma_{i}^A$. These prior parameters are sampled in turn from their respective hyperpriors: $\mu_{i}^{A}$, from a Gaussian distribution with mean 0 and standard deviation 10, and $\sigma_{i}^A$ from an Exponential distribution with parameters 0.1.
		
		\begin{table}[h]
			\small
			\begin{tabular}{|c|c|c|c|}
				\hline
				Parameter & Prior & Hyperparameters & Hyperpriors \\
				\hline
				information bonus, $A_{is}$ 
				& $A_{is} \sim $  Gaussian($\mu_i^{A}$, $\sigma_i^{A}$) 
				& $\theta_{i}^{A} = (\mu_i^{A}, \sigma_i^{A}) $
				& \specialcell{
					$\mu_i^{A} \sim $ Gaussian( 0, 100 ) \\ 
					$\sigma_i^{A} \sim $ Exponential(0.01)}		\\
				\hline
				spatial bias, $b_{is}$ 
				& $b_{is} \sim $  Gaussian($\mu_i^{b}$, $\sigma_i^{b}$) 
				& $\theta_{i}^{b} = (\mu_i^{b}, \sigma_i^{b}) $
				& \specialcell{
					$\mu_i^{b} \sim $ Gaussian( 0, 100 ) \\ 
					$\sigma_i^{b} \sim $ Exponential(0.01)}		\\
				\hline
				deviation of deterministic noise, $\sigma^{det}_{isg}$ 
				& $\sigma^{det}_{is} \sim $  Gamma($k_i^{det}$, $\lambda_{i}^{det}$) 
				& $\theta_{i}^{det} = (k_i^{det}, \lambda_i^{det}) $
				& \specialcell{
					$k_i^{det} \sim $ Exponential(0.01) \\ 
					$\lambda_i^{det} \sim $ Exponential(10)}		\\
				\hline
				deviation of random noise, $\sigma^{ran}_{isgr}$ 
				& $\sigma^{ran}_{is} \sim $  Gamma($k_i^{ran}$, $\lambda_{i}^{ran}$) 
				& $\theta_{i}^{ran} = (k_i^{ran}, \lambda_i^{ran}) $
				& \specialcell{
					$k_i^{ran} \sim $ Exponential(0.01) \\ 
					$\lambda_i^{ran} \sim $ Exponential(10)}		\\
				\hline
			\end{tabular}
			\caption{Model parameters, priors, hyperparameters and hyperpriors. }%CHECK UPDATE}
		\label{tab:pars2}	
	\end{table}
	
	\subsubsection*{Model fitting using MCMC}
	The model was fit to the data using Markov Chain Monte Carlo approach implemented in the JAGS package \citep{jags} via the MATJAGS interface (psiexp.ss.uci.edu/research/programs\_data/jags). This package approximates the posterior distribution over model parameters by generating samples from this posterior distribution given the observed behavioral data.  
	
	In particular we used 10 independent Markov chains to generate 50000 samples from the posterior distribution over parameters (5000 samples per chain).  Each chain had a burn in period of 5000 samples, which were discarded to reduce the effects of initial conditions, and posterior samples were acquired at a thin rate of 1.  Convergence of the Markov chains was confirmed {\it post hoc} by eye. 
	
	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=1\textwidth]{figures/EEHorizon_2sigma.pdf}
			\caption{Schematic of the hierarchical Bayesian model using notation of \cite{lee_wagenmakers_2014}}
			\label{fig:model}
		\end{center}
	\end{figure}
	
	\subsection*{Data and code}
	Behavioral data as well as MATLAB codes to recreate the main figures from this paper will be made available upon publication. %website at https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/CZT6EE.
	
	
	\bibliographystyle{plainnat}
	%\bibliographystyle{unsrt}
	\bibliography{Refs/refs}
	
	% add the Bibliography to the Table of Contents
	\cleardoublepage
	\ifdefined\phantomsection
	\phantomsection  % makes hyperref recognize this section properly for pdf link
	\else
	\fi
	\addcontentsline{toc}{chapter}{Bibliography}
	
	
	%\listofchanges
	
\end{document}
